{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c8fb504",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a95c1",
   "metadata": {},
   "source": [
    "Classification is a technique or model which attempts to get some conclusion from observed values in classification problem. Models which perform classification tasks are usually called Classifiers. Classifiers are usually used in face recognition, spam identification etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d75d48",
   "metadata": {},
   "source": [
    "# Steps for building a Classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57636e33",
   "metadata": {},
   "source": [
    "## STEP 1: Import scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac34fac5",
   "metadata": {},
   "source": [
    "Sklearn is a very powerful Machine LearningLibrary with in-built data sets and also support for all major Machine Learning ALgorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4dd0a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e97ff2",
   "metadata": {},
   "source": [
    "## STEP 2: Import Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52809910",
   "metadata": {},
   "source": [
    "We will be making use of sklearn's inbuilt datasets. Here we will be making use of scikit-learns inbuilt breast cancer Wisconsin Diagnostic Dataset. The data set includes information about breast cancer tumours as well as classification labels of malignant or benign. The dataset contains 569 instances or data. 569 tumours and includes information o 30 attributes or features such as radius of the tumour, texture, smoothness etc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d48ed059",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the dataset\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "#now we load the dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04f4d1e",
   "metadata": {},
   "source": [
    "#### Keys for the data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43323e8e",
   "metadata": {},
   "source": [
    "Below are important dictionary keys for the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4989f2",
   "metadata": {},
   "source": [
    "Classification Label Names(target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5398ca",
   "metadata": {},
   "source": [
    "The actual labels(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4548d401",
   "metadata": {},
   "source": [
    "The Attribute/feature names(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55699c6f",
   "metadata": {},
   "source": [
    "The attribute (data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701271aa",
   "metadata": {},
   "source": [
    "Now with the help of the keywords above we can assign variables to important parts of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "874e26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = data['target_names']\n",
    "\n",
    "labels = data['target']\n",
    "\n",
    "feature_names = ['feature_names']\n",
    "\n",
    "features = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed03a941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n"
     ]
    }
   ],
   "source": [
    "#we wil print the label names so we can have a clearer look at what we are looking at\n",
    "print(label_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21c8783",
   "metadata": {},
   "source": [
    "## STEP 3: Organizing Data into sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6f1b8a",
   "metadata": {},
   "source": [
    "Next we will split the data into training sets and test sets in order to be able to test our model on unseen data. we will use 40% of our data to test our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df41bc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we will import sklearns train_test_split function\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Now we will split the data\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=0.40, random_state=42) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4233cc95",
   "metadata": {},
   "source": [
    "## STEP 4: Building a classifier model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be942bef",
   "metadata": {},
   "source": [
    "Later on we will build several classifiers but for now we are going to make use of the Naive Bayes Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12ef89c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "001fdac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now to initialize it\n",
    "gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f124e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we are going to fir the model with our training data\n",
    "model = gnb.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255b4ba3",
   "metadata": {},
   "source": [
    "## Evaluating the Model using performance measures  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639033bc",
   "metadata": {},
   "source": [
    "We are going to get the predictions of our model and get the score of it  using several performance measures, F1 score, recall, precision and accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53c6e96",
   "metadata": {},
   "source": [
    "First we are going to find the prdictions for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38e5780f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1 0 1 0 1 1 1 1 0 1 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 0 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "prediction = gnb.predict(test_data)\n",
    "#now we are goig to output the prediction of the dataset\n",
    "print(\"Prediction:\")\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d332ea58",
   "metadata": {},
   "source": [
    "The above series of 0s and 1s are the predicted values for the tumour classes; malignant and benign."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bf8a98",
   "metadata": {},
   "source": [
    "Now by comparing the two classes test_labels and prediction we can get arguments for our performance measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "912c6fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the performance_measure\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548ed8bd",
   "metadata": {},
   "source": [
    "Now we will explain each of the performance measures we just imported"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5465639d",
   "metadata": {},
   "source": [
    "#### Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251d13be",
   "metadata": {},
   "source": [
    "This is simply the number of predictions our model got right compared to the total number of predictions in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "81d50340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:\n",
      "0.9517543859649122\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(test_labels, prediction) \n",
    "print(\"Accuracy score:\")\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e186aeb5",
   "metadata": {},
   "source": [
    "#### Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2959084",
   "metadata": {},
   "source": [
    "This is simply the number of true predictions a model made out of the total predictions it made it is displayed as true predictions/true predictions + false predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93cd89c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Score:\n",
      "0.9536423841059603\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(test_labels, prediction)\n",
    "print(\"Precision Score:\")\n",
    "print(precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d12d06",
   "metadata": {},
   "source": [
    "#### Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248aaaee",
   "metadata": {},
   "source": [
    "This is somehow similar to precision but recall is simly the total number of true predictions a model makes out of the total true predictions. it is expressed as, model predictions/ model predictions that are true and model predictions that are false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96e03d62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:\n",
      "0.972972972972973\n"
     ]
    }
   ],
   "source": [
    "recall = recall_score(test_labels, prediction)\n",
    "print(\"Recall:\")\n",
    "print(recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef7eea7",
   "metadata": {},
   "source": [
    "#### F1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed0c09e",
   "metadata": {},
   "source": [
    "This is simply the median of precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92037677",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score\n",
      "0.9632107023411371\n"
     ]
    }
   ],
   "source": [
    "f1 = f1_score(test_labels, prediction)\n",
    "print(\"F1 Score\")\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d184d868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
