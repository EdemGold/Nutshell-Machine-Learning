{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acfc1f8a",
   "metadata": {},
   "source": [
    "# Feature Importance Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5789e06",
   "metadata": {},
   "source": [
    "Here we will build a simple Logistic Regressiion classifier and use all the features of the data to make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dbaaddd",
   "metadata": {},
   "source": [
    "Then we will build another one which makes useof those features picked by importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f254c8c9",
   "metadata": {},
   "source": [
    "## Evaluation of a model using all Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11d43459",
   "metadata": {},
   "outputs": [],
   "source": [
    "#some code was gotten from machinelearningmastery.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef4f21e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "[1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0 1 1 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 0 0 1 1 1 1 1 0 0\n",
      " 1 1 1 0 0 1 0 1 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 1 1 0 1 0 1 0 1\n",
      " 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 1 1 0 0 1 1 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 1 0\n",
      " 0 0 0 1 1 1 0 1 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 0 1 1 1\n",
      " 1 1 1 0 0 1 0 0 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0]\n",
      "Accuracy Score:\n",
      "0.9363636363636364\n"
     ]
    }
   ],
   "source": [
    "# evaluation of a model using all features\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# define the dataset\n",
    "x, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "# fit the model\n",
    "model = RandomForestClassifier()\n",
    "model.fit(x_train, y_train)\n",
    "# evaluate the model\n",
    "prediction= model.predict(x_test)\n",
    "#show prediction\n",
    "print(\"Prediction:\")\n",
    "print(prediction)\n",
    "# show accuraacy of model prediction\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print('Accuracy Score:')\n",
    "print(accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158418e4",
   "metadata": {},
   "source": [
    "## Evaluation of Model using only Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea5768a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction:\n",
      "[1 0 0 0 0 0 1 0 0 1 0 1 1 0 1 1 1 1 1 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 1 1 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 1 1 1 1 0 1 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 0 1 1 0 0 1 1 0 0 1 1 0 0 0 1 0 1 0 0 1 1 0 1 0 1 0 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 0 1 1 1 0 1 0 1 0 0 0 1 0 0 0 0 0 1 0 1 0 1 0 0 0 0 1 1 1 1 1 0 0\n",
      " 1 1 1 1 0 1 0 0 0 0 1 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 1 0 1 0 1 0 1\n",
      " 1 0 1 1 0 0 1 1 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 1 1\n",
      " 1 1 1 1 1 0 0 0 1 1 0 1 1 0 0 0 0 1 0 0 0 1 0 0 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
      " 0 0 0 1 1 1 0 1 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 1 1 1\n",
      " 1 1 1 0 1 1 0 1 1 1 1 1 1 1 0 1 1 0 1 1 1 0 1 0 1 0 0 0 1 1 1 1 1 0]\n",
      "Accuracy 0.9\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import make_classification \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#feature selection function\n",
    "def select_features(x_train, y_train, x_test):\n",
    "\t# configure to select a subset of features\n",
    "\tfs = SelectFromModel(RandomForestClassifier(n_estimators=1000), max_features=5)\n",
    "\t# learn relationship from training data\n",
    "\tfs.fit(x_train, y_train)\n",
    "\t# transform train input data\n",
    "\tx_train_fs = fs.transform(x_train)\n",
    "\t# transform test input data\n",
    "\tx_test_fs = fs.transform(x_test)\n",
    "\treturn x_train_fs, x_test_fs, fs\n",
    "\n",
    "\n",
    "#define the dataset\n",
    "x, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_redundant=5, random_state=1)\n",
    "#split the data\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=1)\n",
    "#feature_selection\n",
    "x_train_fs, x_test_fs, fs = select_features(x_train, y_train, x_test)\n",
    "#fit the model\n",
    "model = RandomForestClassifier()\n",
    "#fit the model\n",
    "model.fit(x_train_fs, y_train)\n",
    "#model prediction\n",
    "prediction = model.predict(x_test_fs)\n",
    "#show prediction\n",
    "print(\"Prediction:\")\n",
    "print(prediction)\n",
    "#show accuracy of model prediction\n",
    "accuracy = accuracy_score(y_test, prediction)\n",
    "print(\"Accuracy\", str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3a5589",
   "metadata": {},
   "source": [
    "So in the first code block (\"Evaluation of a model using all Features\") we got an accuracy of 0.93 and in the second code block (\"Evaluation of Model using only Selected Features\") we got an accuracy of  0.9 which is similar to the first acuracy but in the second code block we use only 5 features compared to all 10 features used in the first code block. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e94da4",
   "metadata": {},
   "source": [
    "So using simple inference we have made use o the core important features in the code block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5f2217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
